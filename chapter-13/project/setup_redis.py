from src.constants.constant import DATA_PATH
from src.models.trie import BasicTrie, TrieToHashConverter
from src.utils.utils import trim_word_text

import redis
import os
import time
import gc


def connect_redis():
    """Redis ì—°ê²° ì„¤ì •"""
    redis_host = os.getenv("REDIS_HOST", "localhost")
    redis_port = int(os.getenv("REDIS_PORT", "6379"))
    max_retries = 15
    retry_delay = 3

    for i in range(max_retries):
        try:
            r = redis.Redis(
                host=redis_host,
                port=redis_port,
                db=0,
                decode_responses=True,
                socket_connect_timeout=10,
                socket_timeout=30,
                retry_on_timeout=True
            )
            r.ping()
            print("âœ… Redis connected successfully!")
            return r
        except redis.exceptions.ConnectionError as e:
            print(f"âŒ Redis connection failed (attempt {i + 1}/{max_retries}): {e}")
            time.sleep(retry_delay)

    raise Exception("âŒ Could not connect to Redis after multiple retries.")


def check_existing_data(redis_client):
    """ê¸°ì¡´ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    try:
        if redis_client.get("trie:setup_complete") == "true":
            sample_keys = redis_client.keys("trie:*")
            if len(sample_keys) > 10:
                print("âœ… Redis data already exists, skipping setup")
                return True
        return False
    except Exception as e:
        print(f"âš ï¸ Error checking Redis data: {e}")
        return False


def clear_existing_data(redis_client):
    """ê¸°ì¡´ ë°ì´í„° ì‚­ì œ"""
    print("ğŸ”„ Force setup mode - rebuilding data")
    trie_keys = redis_client.keys("trie:*")
    if trie_keys:
        # ë°°ì¹˜ ì‚­ì œë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
        batch_size = 1000
        for i in range(0, len(trie_keys), batch_size):
            batch = trie_keys[i:i + batch_size]
            redis_client.delete(*batch)
        print(f"ğŸ§¹ Deleted {len(trie_keys)} old keys")


def build_trie():
    """Trie êµ¬ì¡° ë¹Œë“œ"""
    print("ğŸ—ï¸ Building trie structure...")
    word_and_frequency = trim_word_text(DATA_PATH / 'raw' / 'count_1w.txt')
    basic_trie = BasicTrie()
    total_words = 0

    for word, frequency in word_and_frequency:
        basic_trie.insert(word, frequency)
        total_words += 1
        if total_words % 10000 == 0:
            print(f"   Processed {total_words} words...")

    # ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ trie ìµœì í™”
    basic_trie.search('go')
    basic_trie.search('google')

    print(f"âœ… Trie built with {total_words} words")
    return basic_trie, total_words


def store_to_redis_chunked(basic_trie, redis_client):
    """
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ Redis ì €ì¥
    - ì²­í¬ ë‹¨ìœ„ë¡œ cache ìƒì„±í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ
    """
    print("ğŸ’¾ Storing to Redis with memory optimization...")

    batch_size = int(os.getenv('BATCH_SIZE', '500'))
    converter = TrieToHashConverter(basic_trie)

    # ì „ì²´ cacheë¥¼ í•œë²ˆì— ë¹Œë“œí•˜ì§€ ì•Šê³  ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    print("ğŸ”§ Building cache in chunks to save memory...")

    try:
        # ì „ì²´ ìºì‹œ ë¹Œë“œ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•„ìš”)
        trie_cache = converter.build_cache()
        print(f"ğŸ“Š Cache built: {len(trie_cache)} prefixes")

        # ì²­í¬ ë‹¨ìœ„ë¡œ Redisì— ì €ì¥
        stored_keys = store_cache_in_batches(trie_cache, redis_client, batch_size)

        # ë©”ëª¨ë¦¬ í•´ì œ
        del trie_cache
        gc.collect()

        return stored_keys

    except MemoryError:
        print("âš ï¸ Memory error occurred, trying alternative approach...")
        # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ëŒ€ì•ˆ ë°©ë²• (êµ¬í˜„ í•„ìš”)
        return store_without_full_cache(basic_trie, redis_client)


def store_cache_in_batches(trie_cache, redis_client, batch_size):
    """ìºì‹œë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ Redisì— ì €ì¥"""
    print(f"ğŸ”„ Transferring cache to Redis (batch size: {batch_size})...")

    stored_keys = 0
    cache_items = list(trie_cache.items())
    total_items = len(cache_items)

    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for i in range(0, total_items, batch_size):
        batch = cache_items[i:i + batch_size]

        # Redis íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
        pipe = redis_client.pipeline()

        for prefix, suggestions in batch:
            zadd_data = {
                suggestion["word"]: suggestion["frequency"]
                for suggestion in suggestions
            }
            pipe.zadd(f"trie:{prefix}", zadd_data)
            stored_keys += 1

        # ë°°ì¹˜ ì‹¤í–‰
        pipe.execute()

        # ì§„í–‰ìƒí™© ì¶œë ¥
        progress = (i + len(batch)) / total_items * 100
        print(f"   Progress: {stored_keys}/{total_items} ({progress:.1f}%)")

        # ë°°ì¹˜ ë©”ëª¨ë¦¬ í•´ì œ
        del batch
        if i % (batch_size * 10) == 0:  # 10ë°°ì¹˜ë§ˆë‹¤ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()

    return stored_keys


def store_without_full_cache(basic_trie, redis_client):
    """
    ì „ì²´ ìºì‹œë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì§€ ì•ŠëŠ” ëŒ€ì•ˆ ë°©ë²•
    (BasicTrie í´ë˜ìŠ¤ê°€ ì§€ì›í•œë‹¤ë©´)
    """
    # ì´ ë¶€ë¶„ì€ BasicTrie í´ë˜ìŠ¤ì˜ êµ¬ì¡°ì— ë”°ë¼ êµ¬í˜„ í•„ìš”
    # í˜„ì¬ëŠ” ê¸°ë³¸ ë°©ë²•ìœ¼ë¡œ fallback
    print("ğŸ”„ Using fallback method...")
    converter = TrieToHashConverter(basic_trie)
    trie_cache = converter.build_cache()
    return store_cache_in_batches(trie_cache, redis_client, 500)


def finalize_setup(redis_client, stored_keys, total_words, elapsed_time):
    """ì„¤ì • ì™„ë£Œ ì²˜ë¦¬"""
    redis_client.set("trie:setup_complete", "true")
    redis_client.set("trie:total_keys", stored_keys)
    redis_client.set("trie:total_words", total_words)

    print(f"âœ… Setup completed in {elapsed_time:.2f} seconds")
    print(f"ğŸ“Š Stored {stored_keys} prefixes for {total_words} words")


def test_suggestions(redis_client):
    """ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ” Testing suggestions:")
    test_prefixes = ["go", "goo", "goog", "googl", "google"]

    for prefix in test_prefixes:
        suggestions = redis_client.zrevrange(f"trie:{prefix}", 0, 4)
        print(f"   {prefix}: {suggestions}")


def setup_trie_data():
    """ë©”ì¸ ë°ì´í„° ì„¤ì • ë¡œì§"""
    start_time = time.time()

    # Redis ì—°ê²°
    redis_client = connect_redis()

    # ê°•ì œ ì„¤ì • ëª¨ë“œ í™•ì¸
    force_setup = os.getenv("FORCE_REDIS_SETUP", "false").lower() == "true"

    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    if not force_setup and check_existing_data(redis_client):
        return redis_client

    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í•„ìš”ì‹œ)
    if force_setup:
        clear_existing_data(redis_client)

    # Trie ë¹Œë“œ
    basic_trie, total_words = build_trie()

    # Redis ì €ì¥ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
    stored_keys = store_to_redis_chunked(basic_trie, redis_client)

    # ì„¤ì • ì™„ë£Œ
    elapsed_time = time.time() - start_time
    finalize_setup(redis_client, stored_keys, total_words, elapsed_time)

    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del basic_trie
    gc.collect()

    return redis_client


if __name__ == '__main__':
    try:
        # ë©”ì¸ ì„¤ì • ì‹¤í–‰
        redis_client = setup_trie_data()

        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_suggestions(redis_client)

        print("ğŸš€ Setup process completed successfully!")

    except Exception as e:
        print(f"âŒ Setup failed: {e}")
        raise
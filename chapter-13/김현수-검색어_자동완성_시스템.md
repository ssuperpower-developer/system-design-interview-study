구글 검색창에서 입력하는 단어에 맞춰 검색어가 자동으로 완성되는 것을 볼 수 있다.
이 기능을 autocomplete, typeahead 등으로 부른다.

많이 이용된 검색어 k개를 자동완성하여 출력하는 시스템을 설계해보자.

## 문제 이해 및 설계 범위 확정

### Questions

1. 사용자가 입력하는 단어는 자동완성될 검색어의 첫 부분이어야 하나요? 아니면 중간 부분이 될 수도 있겠습니까? -> 첫 부분 한정
2. 몇 개의 자동완성 검색어가 표시되어야합니까? -> 5개
3. 자동완성 검색어 5개를 고르는 기준은 무엇입니까? -> 질의 빈도에 따라 정해지는 검색어 인기순위
4. 맞춤법 검사 기능도 제공해야합니까? -> no
5. 질의는 영어입니까? -> yes, 그러나 다국어 지원도 고려해보면 좋음
6. 대문자나 특수문자 처리도 해야합니까? -> no, only small character
7. 얼마나 많은 사용자를 지원해야합니까? -> DAU 기준으로 1000만 이상

### 요구사항

1. 빠른 응답속도: 시스템 응답속도는 100ms이내
2. 연관성: 자동완성되어 출력되는 검색어는 사용자가 입력한 단어와 연관된 것이어여한다.
3. 정렬: 시스템의 계산결과는 인기도 등의 순위 모델로 정렬되어있어야한다
4. 규모 확장성: 시스템은 많은 트래픽을 감당할 수 있도록 확장가능해야한다
5. 고가용성: 시스템의 일부에 장애가 발생하거나, 느려지거나, 예상치 못한 네트워크 문제가 생겨도 시스템은 계속 사용 가능해야한다.

### 개략적 규모 추정

1. 일간 능동 사용자(DAU)는 1000만명 가정
2. 평균적으로 한 사용자는 매일 10건의 검색 수행 가정
3. 질의할 때마다 평균적으로 20바이트의 데이터 입력 가정
    - 문자 인코딩은 ASCII 가정, 1문자는 1 byte
    - 질의문은 평균적으로 4개 단어로 가정, 각 단어는 5개의 글자로 구성된다고 가정
    - 질의 당 평균 4 * 5 = 20 bytes
4. 검색창에 글자를 입력할 때마다 클라이언트는 검색어 자동완성 백엔드에 요청을 보냄

예시  
{base_url}search?q=d  
{base_url}search?q=di  
{base_url}search?q=din  
{base_url}search?q=dinn  
{base_url}search?q=dinne  
{base_url}search?q=dinner  

1. 대략 초당 24000건의 질의(QPS) 발생 (1000만 사용자, 10개의 질의, 20자의 질의 바이트, 24시간, 3600초) 1000000 x 10 x 20 / 24 x 3600 -> 약 24000
2. 최대 QPS는 적당히 2배 곱해서 48000이라고 가정
3. 질의 중 20%는 신규 검색어라고 가정. 따라서 대략 0.4GB(10000000 x 10 x 20 x 0.2 bytes) 정도의 신규 데이터가 시스템에 추가

## 개략적 설계안 제시 및 동의 구하기

개략적으로 시스템은 두 부분으로 나뉜다.

1. 데이터 수집 서비스
사용자가 입력한 질의를 실시간으로 수집하는 시스템. 데이터가 많은 애플리케이션에 실시간 시스템은 그다지 바람직하지 않지만, 설계안을 만드는 출발점으로는 괜찮을 것 같다.
2. 질의 서비스
주어진 질의에 다섯 개의 인기 검색어를 정렬해 내놓는 서비스

### 데이터 수집 서비스

빈도 테이블이 있다고 가정
처음의 테이블을 비어있지만 최종 쿼리를 하나씩 넣고 count하는 counter 자료구조이다
key는 쿼리
value는 빈도수

사용자가 twitch , twitter, twit-ter, twillo를 순서대로 검색할때의 테이블을 보여준다.

![image.png](./images/image%20(4).png)

### 질의 서비스

![image.png](./images/image%20(5).png)

빈도 테이블에 질의(현재까지 입력된 쿼리)를 해서 그것의 top 5를 골라내는 방법

```sql
SELECT *
FROM frequency_table
WHERE query LIKE 'prefix%'
ORDER BY frequency DESC
LIMIT 5
```

사용자의 인터페이스에서는 이런 느낌일 것이다.

![image.png](./images/image%20(6).png)


이렇게 관계형 데이터베이스에 정규식으로 검색을 해도 되지만
잠시 생각을 해봤을 때 대규모의 데이터가 저장되어있는 데이터베이스에

1. 정규식으로 검색을 하고
2. 정렬을 한다

이 두개의 연산이 상당히 cost하다는 것은 금새 알 수 있다.

다만 책에 있는 내용 외에 시간복잡도 분석을 해보자

첫번째는 전체 테이블을 돌아야하므로 O(n)은 반드시 소모된다.
정렬은 아무리 빨라도 O(nlogn)이다.
따라서 최종 시간복잡도는 O(nlogn)이다.

그래서 QPS가 24000을 지원해야하는 서비스에서 매번 정렬을 수행하는 것은 좋은 선택지가 아니다.

## 상세설계

앞선 설계는 출발점으로는 나쁘지 않은 안이지만, 아래 컴포넌트를 골라 상세히 설계하고 다음 순서로 최적화 방안을 논의할 것이다.

1. 트라이(trie) 자료구조
2. 데이터 수집 서비스
3. 질의 서비스
4. 규모 확장이 가능한 저장소
5. 트라이 연산

### 트라이 자료구조

트라이는 문자열들을 간략하게 저장할 수 있는 자료구조이다. 트라이라는 이름은 'retrieval'이라는 단어에서 온 것인데, 문자열을 꺼내는 연산에 초점을 맞추어 설계된 자료구조임을 미루어 짐작할 수 있다.

트라이 자료구조의 핵심 아이디어

1. 트라이는 트리 형태의 자료구조이다
2. 이 트리의 루트 노드는 빈 문자열을 나타낸다
3. 각 노드는 글자 하나를 저장하면 26개의 자식 노드를 가질 수 있다
4. 각 트리 노드는 하나의 단어, 또는 접두어 문자열을 나타낸다


실제 예시를 보면서 트라이 자료구조를 이해해보자. 아래와 같은 빈도 테이블이 있다고 하자.

![image.png](./images/image%20(12).png)

tree, try, true, toy, wish, win이 보관된 트라이
이 빈도 정보를 트라이 노드에 저장하면 아래의 그림과 같은 상태가 된다.

![image.png](./images/image%20(8).png)

기본 트라이 자료구조에서 노드에 문자들을 저장한다. 트라이 노드에 이용빈도를 추가하여 빠르게 count개수를 반환할 수 있다.


트라이의 기본 구조에 대해 설명했다. 이 트라이로의 자동완성은 어떻게 구현할 수 있을까?

용어를 기억하자.

p: 접두어 (prefix)의 길이
n: 트라이 안에 있는 노드 개수
c: 주어진 노드의 자식 노드 개수

**가장 많이 사용된 질의어 k개를 찾는 방법**

1. 해당 접두어를 표현하는 노드를 찾는다. O(p)
2. 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다. 유효한 검색 문자열을 구성하는 노드가 유효 노드다. 시간 복잡도는 O(c)이다
3. 유효 노드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다. 시간 복잡도는 O(c logc)이다

만약, k = 2 이고 검색창에 be를 입력했다고 가정하면 이렇게 동작한다.

![image.png](./images/image%20(9).png)


1. 접두어 노드 be 탐색
2. 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 탐색, 이때 유효 노드는
beer: 10 / best: 35 / bet: 29
3. 유효 노드를 정렬하여 2(=k)개만 골라낸다. best 35 / bet 29가 k값에 의하여 검색된 be에 대한 인기 검색어 2개

이 알고리즘은 직관적이지만, 최악의 경우에는 k개의 결과를 얻으려고 전체 트라이를 다 검색해야하는 일이 생길 수 있음

이 문제를 해결할 방법으로는 두 가지가 있다

1. 접두어의 최대 길의를 제한
2. 각 노드에 인기 검색어를 캐시

### solution 1: 접두어의 최대 길이를 제한

사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없다. 따라서 p값은 작은 정수값 (ex 50)이라고 가정해도 안전하다. 검색어의 최대 길의를 제한할 수 있다면 접두어 노드를 찾는 단계의 시간 복잡도는 O(p)에서 O(50)이 upper bound가 되므로 O(1) 상수시간으로 제한

### solution 2: 노드에 인기 검색어 캐시

각 접두어 노드에다가 k개의 인기검색어를 캐시해서 하위 트라이 구조를 탐색할 필요를 없게 둔다.
노드의 공간복잡도가 늘어나지만, 시간복잡도를 엄청나게 아낄 수 있음


두 개의 솔루션을 통해 전체 서비스의 시간복잡도는 O(1)이 된다.
1. solution 1에 따라 접두어 노드를 찾는데 O(50)의 시간복잡도이므로 빅오 표기법에 의해 O(1) 시간복잡도이다.
2. solution 2에 따라 최고 인기 검색어 5개를 찾는 질의가 결국 접두어 노드를 찾으면 해당 노드에 캐시가 되어있는 k개의 검색어를 가져오기만 하면 되어서 O(1) 시간복잡도이다.

![image.png](./images/image%20(10).png)


### 데이터 수집 서비스

사용자가 검색창에 뭔가 타이핑을 할 때 실시간으로 데이터를 수정했다. 이 방법은 **두가지 문제점**이 있다.

1. 매일 수천만 건의 질의가 입력될텐데, 그 때마다 트라이를 갱신하면 질의 서비스는 심각하게 느려질 것이다.
2. 일단 트라이가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않을 것이다. 그러니 트라이는 그렇게 자주 갱신할 필요가 없다

규모 확장이 쉬운 데이터 수집 서비스를 만드려면 데이터가 어디서 오고 어떻게 이용되는지 살펴야한다. 트위터 같은 실시간 애플리케이션이라면 제안되는 검색어를 항상 신선하게 유지할 필요가 있을 수 있겠지만 구글 검색같은 애플리케이션이라면 그렇게 자주 바꿔줄 이유는 없다.

용례가 달라지더라도 데이터 수집 서비스의 토대는 바뀌지 않을 것이다. 트라이를 만드는데 쓰는 데이터는 보통 데이터 분석 서비스나 로깅 서비스로부터 올 것이기 때문이다.


### 데이터 분석 서비스 로그

![image.png](./images/image%20(12).png)

데이터 분석 서비스 로그에는 검색창에 입력된 질의에 관한 원본데이터가 보관.
새로운 데이터가 추가될분 수정은 이루어지지 않으며 로그 데이터에 인덱스를 걸지 않는다.


데이터 분석 서비스 로그는 초당 24000개의 검색어 로그가 쌓이는 공간. 
대충 한 행당 8 bytes x 24000 x 3600(한시간) x 24 하루에 1.5 TB씩 쌓인다.

우선 데이터 분석 서비스 로그 초당 24000개의 데이터가 쌓이기만하고, 수정은 되지 않는 특수한 컴포넌트이기 때문에 데이터베이스를 사용하지 않고 파일시스템을 통해 구성해야 할 겁니다. 또한 데이터 유실이 그렇게 중요하지 않기도 하고, 정기적으로 데이터를 날리기도 할겁니다.

### 로그 취합 서버

데이터 분석 서비스로부터 나오는 로그는 보통 그 양이 엄청나고 데이터 형식도 제각각인 경우가 많다. 따라서 이 데이터를 잘 취합하여 우리 시스템이 쉽게 소비할 수 있도록 해야한다.  

쉽게 이야기하자면 로그들을 aggregation해서 key는 query, value는 count로 바꿔주는 식으로 트라이에 적용하기 위한 데이터로 변환하는 역할을 담당합니다.

![image.png](./images/image%20(5).png)

이런 느낌으로 트라이를 새로 만들 수 있도록 매일 쌓이는 1.5TB에서 이렇게 k-v table로 만들어야한다. 그걸 로그 취합서버가 하는 것이다.

데이터 취합 방식은 우리 서비스의 용례에 따라 달라질 수도 있다.
예를 들어 트위터와 같은 실시간 애플리케이션의 경우 결과를 빨리 보여주는 것이 중요
로그 취합서버는 Write 트라이(트라이 데이터베이스)에 비즈니스 요구사항에 따라 매일, 매주, 매달 등등 주기에 맞춰 업데이트하기 위해 방대한 데이터 분석 서비스 로그에서 query별로 count를 한 데이터가 필요하다.


한편 대부분의 경우에는 일주일에 한 번 정도로 로그를 취합해도 충분
여기서 면접장에서 데이터 취합의 실시간성이 얼마나 중요한지 중요한지 확인


### 작업서버

worker는 주기적으로 비동기적 작업을 실행하는 서버 집합이다.  
트라이 자료구조를 만들고, 트라이 데이터베이스에 저장하는 역할을 담당

### 트라이 데이터베이스

트라이 데이터베이스는 지속성 저장소다.
트라이 데이터베이스로 사용할 수 있는 선택지로는 다음의 두 가지가 있다.

1. 문서 저장소
새 트라이를 매주 만들 것이므로, 주기적으로 트라이를 직렬화하여 데이터베이스에 저장할 수 있다. 몽고디비 같은 문서 저장소를 활용하면 이런 데이터를 편리하게 저장할 수 있다
2. 키 값 저장소
트라이는 아래 로직을 적용하면 해시 테이블 형태로 변환 가능하다.
트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환

![image.png](./images/image%20(13).png)

### 트라이 캐시

앞에서 구성한 트라이 데이터베이스는 write용이라고 말하였다.  
트라이 캐시는 read용이다.  

트라이 캐시는 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높이는 구실을 한다. 매주 트라이 데이터베이스의 스냅샷을 떠서 갱신한다

각주: 읽기 트라이를 메모리로 떠서 이걸 사용자가 접근하는 트라이는 이 것. 아무래도 디스크보다 메모리가 더 빠르다. 나라면 이것을 redis로 구성할듯. 그리고 Write 트라이(트라이 데이터베이스) 와 Read 트라이 (트라이 캐시) 간에 직렬화와 역직렬화 구현에 대해서도 생각해보면 좋을 것 같다.


### 질의 서비스

![image.png](./images/image%20(14).png)

이것이 최종 설계이다.

개략적 설계안에서 살펴본 질의 서비스는 데이터베이스를 활용해서 최고 인기 검색어 다섯 개를 골라냈음

1. 검색 질의가 로드밸런서로 전송된다
2. 로드밸런서는 해당 질의를 API서버로 보낸다
3. API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답을 구성한다
4. 데이터가 트라이 캐시에 없는 경우에는 데이터를 데이터베이스에서 가져와 캐시에 채운다. 그래야 다음에 같은 접두어에 대한 질의가 오면 캐시에 보관된 데이터를 사용해 처리할 수 있다. 캐시미스는 캐시 서버의 메모리가 부족하거나 캐시서버에 장애가 있어도 발생할 수 있다.

질의 서비스는 번개처럼 빨라야한다. 이를 위해 다음과 같은 최적화 방안을 생각해보자

1. AJAX 요청
    
    ajax요청의 장점은, 브라우저를 새롭게 새로고침할 필요가 없다는 점이다. 이게 무슨 소리냐면, 리액트처럼 렌더링 새롭게 하지 않고 필요한 데이터만 비동기로 가져와 업데이트 한다는 것이다.
    
2. 브라우저 캐싱
    
    대부분의 경우 자동완성 검색어 제안 결과는 짧은 시간에 자주 바뀌지 않는다. 따라서 제안된 검색어들을 브라우저 캐시에 넣어두면, 후속 질의 결과는 해당 캐시에서 바로 사용할 수 있다. 구글 검색 엔진이 이런 캐시 매커니즘을 사용한다.
    
3. 데이터 샘플링
    
    대규모 시스템에서 모든 질의 결과를 로깅하도록 해 놓으면 CPU 자원과 저장공간 및 리소스 사용이 극심해진다. 데이터 샘플링 기법은 유용하다.
    
    즉, N개 요청 가운데 1개만 로깅하도록 하는 것이다.
    

### 트라이 연산

트라이를 갱신하는데 책에서 제시하는 방법은 두 가지입니다.

1. 매주 한번 갱신
2. 트라이의 각 노드를 개별적으로 갱신

1번이 대규모 시스템 설계 상 용이하지만 기존 데이터와 신규 데이터를 merge해서 update를 해야합니다.  

2번이 트라이의 각 노드를 개별적으로 갱신하는 것인데, 성능이 좋지 않아서 택하지 않는다고 합니다. 아무래도 한 행마다 트라이를 탐색하고, 상위 노드에서 미리 기록해둔 캐시를 수정해야하는 연산이 일어나야하므로 좋은 선택이 아니긴 합니다.

그래서 트라이 데이터베이스를 구현하는 방법으로 책에서는 두 가지 방법을 제안합니다.
앞에서 제시한 문서 저장소, 키-값 저장소 방식이 있다. 앞선 각주에서 말했듯이 저는 Redis를 통한 키-값 저장소 방식으로 read 트라이를 구성할거고, write 트라이에는 어떻게 직렬화할지는 고민을 좀 더 해보면 좋을 것 같네요.  

뭐 그래서 결론은 트라이를 document-store이나 hash-table로 구현하는 건 선택이고, 기존 데이터와 신규 데이터를 취합해서 새로운 write 트라이(영속성)에 새로 트라이를 만들고 그것을 똑같이 만든 read 트라이(트라이 cache)로 분할하는 것이 이 설계의 핵심입니다.


**검색어 삭제**

혐오성이 짙거나, 폭력적이거나, 성적으로 노골적이건, 여러가지로 위험한 질의어를 자동완성 결과에서 제거한다.

트라이 캐시 앞에 필터계층을 두고 부적절한 질의어가 반환되지 않도록 한다.

## 마무리

**Questions**

1. 다국어 지원이 가능하도록 시스템을 확장하려면 어떻게 해야할까?
2. 국가 별로 인기 검색어 순위가 다르다면 어떻게 해야하는가?
3. 실시간으로 변하는 검색어의 추이를 반영하려면 어떻게 해야하나요?

## 3줄 요약

1. 검색어 자동완성은 트라이 자료구조를 통해 구현한다.
2. 로그가 하루 1.5TB씩 쌓이는 로그 저장소, 그것을 취합하여 숫자를 세주는 로그 취합서버, 읽기만 담당하는 트라이 캐시, 정기적으로 새로 트라이를 만들고 영속성을 담당하는 트라이 데이터베이스(쓰기)
3. 놀라운 건 아직 검색어 자동완성만 했다. 검색은 들어가지도 않았다.

## 내가 한 생각

1. 읽기 트라이 구조 redis
2. 쓰기 트라이 구조 mongodb
3. 직렬화와 역직렬화 방식
4. 기존 데이터와 신규 데이터 merge 방식
5. 로그 데이터 rolling이나 계층화, 압축 방식
6. 트렌드 검색어 -> 실시간으로 top 1000 내에 들어가는 검색어는 더욱 빠르게 업데이트
7. 아닌 검색어 -> 하루에 한번 업데이트해도 충분


이거 하면서 재밌어 보이는 주제들

1. 트라이 자료구조
2. 문자열 탐색 알고리즘
3. 해쉬